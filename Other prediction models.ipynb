{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ffe22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DT model\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data_path = \"path/to/your/data/\"\n",
    "df = pd.read_excel(data_path + \"merged_data.xlsx\")\n",
    "df_validation = pd.read_excel(data_path + \"df_validationnew.xlsx\")\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = df[\"no-prog/prog\"]\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "y_validation_encoded = label_encoder.transform(df_validation['no-prog/prog'])\n",
    "\n",
    "# Define selected features\n",
    "selected_features = ['Age', 'hsa-miR-556-3p', 'hsa-miR-3667-5p', 'hsa-miR-141-3p', 'hsa-miR-224-5p',\n",
    "                     'hsa-let-7c-5p', 'hsa-miR-3157-5p', 'hsa-miR-200a-5p']\n",
    "\n",
    "# Initialize lists to keep track of the best models\n",
    "best_models = []\n",
    "\n",
    "# Loop through all possible combinations of the selected features, starting from 3 up to the total number of features\n",
    "for i in range(3, len(selected_features) + 1):\n",
    "    for subset in combinations(selected_features, i):\n",
    "        # Select the current subset of features\n",
    "        X_subset = df[list(subset)]\n",
    "        X_validation_subset = df_validation[list(subset)]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_subset, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Scale the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        X_validation_subset_scaled = scaler.transform(X_validation_subset)\n",
    "\n",
    "        # Apply SMOTE to the training data\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "        # Create a new Decision Tree classifier for each subset of features\n",
    "        dt_clf_subset = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "        # Perform hyperparameter tuning on the resampled data\n",
    "        param_grid_subset = {\n",
    "            'max_depth': [None, 5, 10, 15],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "        }\n",
    "\n",
    "        # Create GridSearchCV\n",
    "        grid_search_subset = GridSearchCV(dt_clf_subset, param_grid_subset, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='roc_auc', n_jobs=-1)\n",
    "        grid_search_subset.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        # Get the best model from the grid search\n",
    "        best_dt_clf_subset = grid_search_subset.best_estimator_\n",
    "\n",
    "        # Evaluate the model on the test and validation sets\n",
    "        y_pred_test = best_dt_clf_subset.predict(X_test_scaled)\n",
    "        y_pred_proba_test = best_dt_clf_subset.predict_proba(X_test_scaled)[:, 1]\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "        y_pred_validation = best_dt_clf_subset.predict(X_validation_subset_scaled)\n",
    "        y_pred_proba_validation = best_dt_clf_subset.predict_proba(X_validation_subset_scaled)[:, 1]\n",
    "        accuracy_validation = accuracy_score(y_validation_encoded, y_pred_validation)\n",
    "        auc_validation = roc_auc_score(y_validation_encoded, y_pred_proba_validation)\n",
    "\n",
    "        # Append the model's performance metrics to the best_models list\n",
    "        best_models.append({\n",
    "            'features': subset,\n",
    "            'accuracy_test': accuracy_test,\n",
    "            'auc_test': auc_test,\n",
    "            'accuracy_validation': accuracy_validation,\n",
    "            'auc_validation': auc_validation\n",
    "        })\n",
    "\n",
    "# Find the best model based on the combined AUC for test and validation datasets\n",
    "best_model_auc = max(best_models, key=lambda x: (x['auc_test'] + x['auc_validation']))\n",
    "\n",
    "# Retrieve the performance metrics for the best model\n",
    "best_features = best_model_auc['features']\n",
    "X_best_subset = df[list(best_features)]\n",
    "X_validation_best_subset = df_validation[list(best_features)]\n",
    "\n",
    "# Split the data into training and testing sets for the best feature set\n",
    "X_train_best, X_test_best, y_train_best, y_test_best = train_test_split(X_best_subset, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the best feature set\n",
    "X_train_best_scaled = scaler.fit_transform(X_train_best)\n",
    "X_test_best_scaled = scaler.transform(X_test_best)\n",
    "X_validation_best_scaled = scaler.transform(X_validation_best_subset)\n",
    "\n",
    "# Apply SMOTE to the best training data\n",
    "X_train_best_resampled, y_train_best_resampled = smote.fit_resample(X_train_best_scaled, y_train_best)\n",
    "\n",
    "# Retrain the model on the best feature set\n",
    "best_dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "best_dt_clf.fit(X_train_best_resampled, y_train_best_resampled)\n",
    "\n",
    "# Predict and evaluate on the test set for the best feature set\n",
    "y_pred_test_best = best_dt_clf.predict(X_test_best_scaled)\n",
    "cm_test_best = confusion_matrix(y_test_best, y_pred_test_best)\n",
    "sensitivity_test_best = cm_test_best[1, 1] / (cm_test_best[1, 1] + cm_test_best[1, 0])\n",
    "specificity_test_best = cm_test_best[0, 0] / (cm_test_best[0, 0] + cm_test_best[0, 1])\n",
    "\n",
    "# Predict and evaluate on the validation set for the best feature set\n",
    "y_pred_validation_best = best_dt_clf.predict(X_validation_best_scaled)\n",
    "cm_validation_best = confusion_matrix(y_validation_encoded, y_pred_validation_best)\n",
    "sensitivity_validation_best = cm_validation_best[1, 1] / (cm_validation_best[1, 1] + cm_validation_best[1, 0])\n",
    "specificity_validation_best = cm_validation_best[0, 0] / (cm_validation_best[0, 0] + cm_validation_best[0, 1])\n",
    "\n",
    "# Print the results for the best model\n",
    "print(f\"Best Model Based on Combined AUC:\")\n",
    "print(f\"Features: {best_features}\")\n",
    "print(f\"Test - Accuracy: {best_model_auc['accuracy_test']:.2f}, AUC: {best_model_auc['auc_test']:.2f}, Sensitivity: {sensitivity_test_best:.2f}, Specificity: {specificity_test_best:.2f}\")\n",
    "print(f\"Validation - Accuracy: {best_model_auc['accuracy_validation']:.2f}, AUC: {best_model_auc['auc_validation']:.2f}, Sensitivity: {sensitivity_validation_best:.2f}, Specificity: {specificity_validation_best:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c13e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55afd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d50ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GBM model\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "data_path = \"path/to/your/data/\"\n",
    "df = pd.read_excel(data_path + \"merged_data.xlsx\")\n",
    "df_validation = pd.read_excel(data_path + \"df_validationnew.xlsx\")\n",
    "\n",
    "RANDOM_STATE = 42  \n",
    "\n",
    "# Assuming df, df_validation, and y are already defined\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_validation_encoded = label_encoder.transform(df_validation['no-prog/prog'])\n",
    "\n",
    "# Define selected features\n",
    "selected_features = ['Age', 'hsa-miR-556-3p', 'hsa-miR-3667-5p', 'hsa-miR-141-3p', 'hsa-miR-224-5p',\n",
    "                     'hsa-let-7c-5p', 'hsa-miR-3157-5p', 'hsa-miR-200a-5p']\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "best_models = []\n",
    "\n",
    "for i in range(3, len(selected_features) + 1):\n",
    "    for subset in combinations(selected_features, i):\n",
    "        X_subset = df[list(subset)]\n",
    "        X_validation_subset = df_validation[list(subset)]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_subset, y_encoded, test_size=0.2, random_state=RANDOM_STATE)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        X_validation_scaled = scaler.transform(X_validation_subset)\n",
    "\n",
    "        smote = SMOTE(random_state=RANDOM_STATE)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "        gbm_clf = GradientBoostingClassifier(random_state=RANDOM_STATE, verbose=1)\n",
    "        grid_search = GridSearchCV(gbm_clf, param_grid, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE), scoring='roc_auc', n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        best_gbm = grid_search.best_estimator_\n",
    "\n",
    "        y_pred_test = best_gbm.predict(X_test_scaled)\n",
    "        y_pred_proba_test = best_gbm.predict_proba(X_test_scaled)[:, 1]\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "        y_pred_validation = best_gbm.predict(X_validation_scaled)\n",
    "        y_pred_proba_validation = best_gbm.predict_proba(X_validation_scaled)[:, 1]\n",
    "        accuracy_validation = accuracy_score(y_validation_encoded, y_pred_validation)\n",
    "        auc_validation = roc_auc_score(y_validation_encoded, y_pred_proba_validation)\n",
    "\n",
    "        best_models.append({\n",
    "            'features': subset,\n",
    "            'best_estimator': best_gbm,  # Store the best estimator\n",
    "            'accuracy_test': accuracy_test,\n",
    "            'auc_test': auc_test,\n",
    "            'accuracy_validation': accuracy_validation,\n",
    "            'auc_validation': auc_validation\n",
    "        })\n",
    "\n",
    "best_model_auc = max(best_models, key=lambda x: (x['auc_test'] + x['auc_validation']))\n",
    "\n",
    "# Extract the features and best estimator (model) of the best model\n",
    "best_features = best_model_auc['features']\n",
    "best_gbm = best_model_auc['best_estimator']  # Assuming you store the best estimator in best_models list\n",
    "\n",
    "# Prepare the dataset with the best features\n",
    "X_best_subset = df[list(best_features)]\n",
    "X_validation_best_subset = df_validation[list(best_features)]\n",
    "\n",
    "# Split and scale the dataset\n",
    "X_train_best, X_test_best, y_train_best, y_test_best = train_test_split(X_best_subset, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train_best_scaled = scaler.fit_transform(X_train_best)\n",
    "X_test_best_scaled = scaler.transform(X_test_best)\n",
    "X_validation_best_scaled = scaler.transform(X_validation_best_subset)\n",
    "\n",
    "# Use the best estimator for predictions without retraining\n",
    "y_pred_test_best = best_gbm.predict(X_test_best_scaled)\n",
    "y_pred_proba_test_best = best_gbm.predict_proba(X_test_best_scaled)[:, 1]\n",
    "y_pred_validation_best = best_gbm.predict(X_validation_best_scaled)\n",
    "y_pred_proba_validation_best = best_gbm.predict_proba(X_validation_best_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_test_best = accuracy_score(y_test_best, y_pred_test_best)\n",
    "auc_test_best = roc_auc_score(y_test_best, y_pred_proba_test_best)\n",
    "accuracy_validation_best = accuracy_score(y_validation_encoded, y_pred_validation_best)\n",
    "auc_validation_best = roc_auc_score(y_validation_encoded, y_pred_proba_validation_best)\n",
    "\n",
    "cm_test_best = confusion_matrix(y_test_best, y_pred_test_best)\n",
    "cm_validation_best = confusion_matrix(y_validation_encoded, y_pred_validation_best)\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "sensitivity_test = cm_test_best[1, 1] / (cm_test_best[1, 1] + cm_test_best[1, 0])\n",
    "specificity_test = cm_test_best[0, 0] / (cm_test_best[0, 0] + cm_test_best[0, 1])\n",
    "sensitivity_validation = cm_validation_best[1, 1] / (cm_validation_best[1, 1] + cm_validation_best[1, 0])\n",
    "specificity_validation = cm_validation_best[0, 0] / (cm_validation_best[0, 0] + cm_validation_best[0, 1])\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Model Based on Combined AUC:\")\n",
    "print(f\"Features: {best_features}\")\n",
    "print(f\"Test - Accuracy: {accuracy_test_best:.2f}, AUC: {auc_test_best:.2f}, Sensitivity: {sensitivity_test:.2f}, Specificity: {specificity_test:.2f}\")\n",
    "print(f\"Validation - Accuracy: {accuracy_validation_best:.2f}, AUC: {auc_validation_best:.2f}, Sensitivity: {sensitivity_validation:.2f}, Specificity: {specificity_validation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22cbfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578673ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "## penalized logistic regression\n",
    "\n",
    "data_path = \"path/to/your/data/\"\n",
    "df = pd.read_excel(data_path + \"merged_data.xlsx\")\n",
    "df_validation = pd.read_excel(data_path + \"df_validationnew.xlsx\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from itertools import combinations\n",
    "\n",
    "# Define your features and target\n",
    "X = df.drop('no-prog/prog', axis='columns')\n",
    "y = df[\"no-prog/prog\"]\n",
    "\n",
    "# The initial set of features\n",
    "all_features = ['Age', 'hsa-miR-556-3p', 'hsa-miR-3667-5p', 'hsa-miR-200a-5p', 'hsa-miR-3157-5p', 'hsa-miR-141-3p',\n",
    "                'hsa-miR-224-5p', 'hsa-let-7c-5p']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "assert set(all_features).issubset(df_validation.columns), \"Validation data is missing some features\"\n",
    "\n",
    "# Make sure all datasets have the same features in the same order\n",
    "X_train = X_train[all_features]\n",
    "X_test = X_test[all_features]\n",
    "X_validation = df_validation[all_features]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "\n",
    "# Standardize the validation data using the same scaler\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "\n",
    "# Dictionary to store performance metrics for each feature subset\n",
    "performance_metrics = {}\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Resample the training data\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "assert len(X_train_resampled) == len(y_train_resampled), \"Mismatch in resampled training set size\"\n",
    "\n",
    "# Create the logistic regression model\n",
    "logreg = LogisticRegressionCV(cv=5, scoring='roc_auc', l1_ratios=[0.5],\n",
    "                              penalty='elasticnet', solver='saga',\n",
    "                              class_weight={0: 1, 1: 1}, random_state=42, max_iter=10000)\n",
    "\n",
    "# Fit the model on the resampled training data\n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Iterate over all possible non-empty combinations of features\n",
    "for i in range(1, len(all_features) + 1):\n",
    "    for subset in combinations(all_features, i):\n",
    "        # Select the current subset of features' indices\n",
    "        subset_indices = [all_features.index(feat) for feat in subset]\n",
    "        \n",
    "        # Standardize the features (if not already done)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_subset_scaled = scaler.fit_transform(X_train.iloc[:, subset_indices])\n",
    "        X_validation_subset_scaled = scaler.transform(X_validation.iloc[:, subset_indices])\n",
    "        X_test_subset_scaled = scaler.transform(X_test.iloc[:, subset_indices])\n",
    "\n",
    "        # Create an instance of RandomOverSampler\n",
    "        ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "        # Resample the training subset\n",
    "        X_train_subset_resampled, y_train_subset_resampled = ros.fit_resample(X_train_subset_scaled, y_train)\n",
    "\n",
    "        # Fit the model on the resampled training subset\n",
    "        logreg.fit(X_train_subset_resampled, y_train_subset_resampled)\n",
    "\n",
    "        # Predict on the validation and test subsets\n",
    "        y_pred_proba_validation = logreg.predict_proba(X_validation_subset_scaled)[:, 1]\n",
    "        y_pred_validation = logreg.predict(X_validation_subset_scaled)\n",
    "        y_pred_proba_test = logreg.predict_proba(X_test_subset_scaled)[:, 1]\n",
    "        y_pred_test = logreg.predict(X_test_subset_scaled)\n",
    "        \n",
    "        # Calculate performance metrics for validation data\n",
    "        auc_validation = roc_auc_score(y_validation, y_pred_proba_validation)\n",
    "        accuracy_validation = accuracy_score(y_validation, y_pred_validation)\n",
    "        cm_validation = confusion_matrix(y_validation, y_pred_validation)\n",
    "        sensitivity_validation = cm_validation[1, 1] / (cm_validation[1, 1] + cm_validation[1, 0])\n",
    "        specificity_validation = cm_validation[0, 0] / (cm_validation[0, 0] + cm_validation[0, 1])\n",
    "        \n",
    "        # Calculate performance metrics for test data\n",
    "        auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "        sensitivity_test = cm_test[1, 1] / (cm_test[1, 1] + cm_test[1, 0])\n",
    "        specificity_test = cm_test[0, 0] / (cm_test[0, 0] + cm_test[0, 1])\n",
    "        \n",
    "        # Store the performance metrics\n",
    "        performance_metrics[subset] = {'AUC Validation': auc_validation, 'Accuracy Validation': accuracy_validation,\n",
    "                                       'Sensitivity Validation': sensitivity_validation, 'Specificity Validation': specificity_validation,\n",
    "                                       'AUC Test': auc_test, 'Accuracy Test': accuracy_test,\n",
    "                                       'Sensitivity Test': sensitivity_test, 'Specificity Test': specificity_test}\n",
    "\n",
    "# Identify the feature subset with the highest AUC and accuracy on validation data\n",
    "best_auc_validation_features = max(performance_metrics, key=lambda x: performance_metrics[x]['AUC Validation'])\n",
    "best_accuracy_validation_features = max(performance_metrics, key=lambda x: performance_metrics[x]['Accuracy Validation'])\n",
    "\n",
    "# Sort the performance metrics dictionary by a combined score of AUC and accuracy for both test and validation data\n",
    "top_combined_models = sorted(performance_metrics.items(), key=lambda x: x[1]['AUC Validation'] * x[1]['Accuracy Validation'] * x[1]['AUC Test'] * x[1]['Accuracy Test'], reverse=True)[:5]\n",
    "\n",
    "# Print the top 5 models with the highest combined score\n",
    "print(\"Top 5 models with the highest combined score:\")\n",
    "for i, (features, metrics) in enumerate(top_combined_models, 1):\n",
    "    print(f\"Model {i}:\")\n",
    "    print(f\"Features: {features}\")\n",
    "    print(f\"AUC Test: {metrics['AUC Test']:.2f}, AUC Validation: {metrics['AUC Validation']:.2f}\")\n",
    "    print(f\"Accuracy Test: {metrics['Accuracy Test']:.2f}, Accuracy Validation: {metrics['Accuracy Validation']:.2f}\")\n",
    "    print(f\"Sensitivity Test: {metrics['Sensitivity Test']:.2f}, Sensitivity Validation: {metrics['Sensitivity Validation']:.2f}\")\n",
    "    print(f\"Specificity Test: {metrics['Specificity Test']:.2f}, Specificity Validation: {metrics['Specificity Validation']:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747032f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584dede1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa700966",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data_path = \"path/to/your/data/\"\n",
    "df = pd.read_excel(data_path + \"merged_data.xlsx\")\n",
    "df_validation = pd.read_excel(data_path + \"df_validationnew.xlsx\")\n",
    "\n",
    "# Create an instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Random Forest classifier\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rf_clf, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best Random Forest classifier from the grid search\n",
    "best_rf_clf = grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model on the resampled training data\n",
    "best_rf_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Iterate over all possible non-empty combinations of features\n",
    "for i in range(1, len(all_features) + 1):\n",
    "    for subset in combinations(all_features, i):\n",
    "        # Select the current subset of features' indices\n",
    "        subset_indices = [all_features.index(feat) for feat in subset]\n",
    "\n",
    "        # Standardize the features (if not already done)\n",
    "        X_train_subset_scaled = scaler.fit_transform(X_train.iloc[:, subset_indices])\n",
    "        X_validation_subset_scaled = scaler.transform(X_validation.iloc[:, subset_indices])\n",
    "        X_test_subset_scaled = scaler.transform(X_test.iloc[:, subset_indices])\n",
    "\n",
    "        # Create an instance of RandomOverSampler\n",
    "        ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "        # Resample the training subset\n",
    "        X_train_subset_resampled, y_train_subset_resampled = ros.fit_resample(X_train_subset_scaled, y_train)\n",
    "\n",
    "        # Fit the model on the resampled training subset\n",
    "        best_rf_clf.fit(X_train_subset_resampled, y_train_subset_resampled)\n",
    "\n",
    "        # Predict on the validation and test subsets\n",
    "        y_pred_proba_validation = best_rf_clf.predict_proba(X_validation_subset_scaled)[:, 1]\n",
    "        y_pred_validation = best_rf_clf.predict(X_validation_subset_scaled)\n",
    "        y_pred_proba_test = best_rf_clf.predict_proba(X_test_subset_scaled)[:, 1]\n",
    "        y_pred_test = best_rf_clf.predict(X_test_subset_scaled)\n",
    "\n",
    "        # Calculate performance metrics for validation data\n",
    "        auc_validation = roc_auc_score(y_validation, y_pred_proba_validation)\n",
    "        accuracy_validation = accuracy_score(y_validation, y_pred_validation)\n",
    "        sensitivity_validation, specificity_validation = calculate_sensitivity_specificity(y_validation, y_pred_validation)\n",
    "\n",
    "        # Calculate performance metrics for test data\n",
    "        auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        sensitivity_test, specificity_test = calculate_sensitivity_specificity(y_test, y_pred_test)\n",
    "\n",
    "        # Store the performance metrics\n",
    "        performance_metrics[subset] = {\n",
    "            'AUC Validation': auc_validation, 'Accuracy Validation': accuracy_validation,\n",
    "            'Sensitivity Validation': sensitivity_validation, 'Specificity Validation': specificity_validation,\n",
    "            'AUC Test': auc_test, 'Accuracy Test': accuracy_test,\n",
    "            'Sensitivity Test': sensitivity_test, 'Specificity Test': specificity_test\n",
    "        }\n",
    "\n",
    "# Sort the performance metrics dictionary by a combined score of AUC and accuracy for both test and validation data\n",
    "top_combined_models = sorted(performance_metrics.items(), key=lambda x: (x[1]['AUC Validation'] * x[1]['Accuracy Validation']) + (x[1]['AUC Test'] * x[1]['Accuracy Test']), reverse=True)[:5]\n",
    "\n",
    "# Print the top 5 models with the highest combined score\n",
    "print(\"Top 5 models with the highest combined score:\")\n",
    "for i, (features, metrics) in enumerate(top_combined_models, 1):\n",
    "    print(f\"Model {i}:\")\n",
    "    print(f\"Features: {features}\")\n",
    "    print(f\"AUC Test: {metrics['AUC Test']:.2f}, AUC Validation: {metrics['AUC Validation']:.2f}\")\n",
    "    print(f\"Accuracy Test: {metrics['Accuracy Test']:.2f}, Accuracy Validation: {metrics['Accuracy Validation']:.2f}\")\n",
    "    print(f\"Sensitivity Test: {metrics['Sensitivity Test']:.2f}, Sensitivity Validation: {metrics['Sensitivity Validation']:.2f}\")\n",
    "    print(f\"Specificity Test: {metrics['Specificity Test']:.2f}, Specificity Validation: {metrics['Specificity Validation']:.2f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c1ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa4c42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine and Kernel Support Vector Machine\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "data_path = \"path/to/your/data/\"\n",
    "df = pd.read_excel(data_path + \"merged_data.xlsx\")\n",
    "df_validation = pd.read_excel(data_path + \"df_validationnew.xlsx\")\n",
    "\n",
    "RANDOM_STATE = 42  # Fixed random state for consistency\n",
    "\n",
    "# Assuming df, df_validation, and y are already defined\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_validation_encoded = label_encoder.transform(df_validation['no-prog/prog'])\n",
    "\n",
    "# Define selected features\n",
    "selected_features = ['Age', 'hsa-miR-556-3p', 'hsa-miR-3667-5p', 'hsa-miR-141-3p', 'hsa-miR-224-5p',\n",
    "                     'hsa-let-7c-5p', 'hsa-miR-3157-5p', 'hsa-miR-200a-5p']\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1,0.5, 1, 5, 10]\n",
    "}\n",
    "\n",
    "best_models = []\n",
    "\n",
    "for i in range(3, len(selected_features) + 1):\n",
    "    for subset in combinations(selected_features, i):\n",
    "        X_subset = df[list(subset)]\n",
    "        X_validation_subset = df_validation[list(subset)]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_subset, y_encoded, test_size=0.2, random_state=RANDOM_STATE)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        X_validation_scaled = scaler.transform(X_validation_subset)\n",
    "\n",
    "        smote = SMOTE(random_state=RANDOM_STATE)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "        svm_clf = SVC(probability=True, random_state=RANDOM_STATE, kernel='rbf', class_weight={0: 1, 1: 1})\n",
    "        grid_search = GridSearchCV(svm_clf, param_grid, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE), scoring='roc_auc', n_jobs=-1)\n",
    "        grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        best_svm = grid_search.best_estimator_\n",
    "\n",
    "        y_pred_test = best_svm.predict(X_test_scaled)\n",
    "        y_pred_proba_test = best_svm.predict_proba(X_test_scaled)[:, 1]\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "        y_pred_validation = best_svm.predict(X_validation_scaled)\n",
    "        y_pred_proba_validation = best_svm.predict_proba(X_validation_scaled)[:, 1]\n",
    "        accuracy_validation = accuracy_score(y_validation_encoded, y_pred_validation)\n",
    "        auc_validation = roc_auc_score(y_validation_encoded, y_pred_proba_validation)\n",
    "\n",
    "        best_models.append({\n",
    "            'features': subset,\n",
    "            'best_estimator': best_svm,\n",
    "            'accuracy_test': accuracy_test,\n",
    "            'auc_test': auc_test,\n",
    "            'accuracy_validation': accuracy_validation,\n",
    "            'auc_validation': auc_validation\n",
    "        })\n",
    "\n",
    "best_model_auc = max(best_models, key=lambda x: (x['auc_test'] + x['auc_validation']))\n",
    "\n",
    "# Retrieve the features and best estimator (model) of the best model\n",
    "best_features = best_model_auc['features']\n",
    "best_svm_estimator = best_model_auc['best_estimator']\n",
    "\n",
    "# Extract the 'C' parameter from the best estimator\n",
    "C_value = best_svm_estimator.get_params()['C']\n",
    "\n",
    "# Prepare the dataset with the best features\n",
    "X_best_subset = df[list(best_features)]\n",
    "X_validation_best_subset = df_validation[list(best_features)]\n",
    "\n",
    "# Split and scale the dataset\n",
    "X_train_best, X_test_best, y_train_best, y_test_best = train_test_split(X_best_subset, y_encoded, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train_best_scaled = scaler.fit_transform(X_train_best)\n",
    "X_test_best_scaled = scaler.transform(X_test_best)\n",
    "X_validation_best_scaled = scaler.transform(X_validation_best_subset)\n",
    "\n",
    "# SMOTE application\n",
    "X_train_best_resampled, y_train_best_resampled = smote.fit_resample(X_train_best_scaled, y_train_best)\n",
    "\n",
    "# Retrain the model using the same 'C' value\n",
    "best_svm = SVC(probability=True, random_state=RANDOM_STATE, C=C_value, kernel='rbf')\n",
    "best_svm.fit(X_train_best_resampled, y_train_best_resampled)\n",
    "\n",
    "# Predict on test and validation set\n",
    "y_pred_test_best = best_svm.predict(X_test_best_scaled)\n",
    "y_pred_proba_test_best = best_svm.predict_proba(X_test_best_scaled)[:, 1]\n",
    "y_pred_validation_best = best_svm.predict(X_validation_best_scaled)\n",
    "y_pred_proba_validation_best = best_svm.predict_proba(X_validation_best_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_test_best = accuracy_score(y_test_best, y_pred_test_best)\n",
    "auc_test_best = roc_auc_score(y_test_best, y_pred_proba_test_best)\n",
    "accuracy_validation_best = accuracy_score(y_validation_encoded, y_pred_validation_best)\n",
    "auc_validation_best = roc_auc_score(y_validation_encoded, y_pred_proba_validation_best)\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "cm_test_best = confusion_matrix(y_test_best, y_pred_test_best)\n",
    "cm_validation_best = confusion_matrix(y_validation_encoded, y_pred_validation_best)\n",
    "sensitivity_test = cm_test_best[1, 1] / (cm_test_best[1, 1] + cm_test_best[1, 0])\n",
    "specificity_test = cm_test_best[0, 0] / (cm_test_best[0, 0] + cm_test_best[0, 1])\n",
    "sensitivity_validation = cm_validation_best[1, 1] / (cm_validation_best[1, 1] + cm_validation_best[1, 0])\n",
    "specificity_validation = cm_validation_best[0, 0] / (cm_validation_best[0, 0] + cm_validation_best[0, 1])\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Model Based on Combined AUC:\")\n",
    "print(f\"Features: {best_features}\")\n",
    "print(f\"Test - Accuracy: {accuracy_test_best:.2f}, AUC: {auc_test_best:.2f}, Sensitivity: {sensitivity_test:.2f}, Specificity: {specificity_test:.2f}\")\n",
    "print(f\"Validation - Accuracy: {accuracy_validation_best:.2f}, AUC: {auc_validation_best:.2f}, Sensitivity: {sensitivity_validation:.2f}, Specificity: {specificity_validation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the best_models list based on the sum of AUC for test and validation\n",
    "sorted_best_models = sorted(best_models, key=lambda x: (x['auc_test'] + x['auc_validation']), reverse=True)\n",
    "\n",
    "# Print the top 5 models\n",
    "print(\"Top 5 Models Based on Combined AUC:\")\n",
    "for i, model in enumerate(sorted_best_models[:5], start=1):\n",
    "    print(f\"Model {i}:\")\n",
    "    print(f\"    Features: {model['features']}\")\n",
    "    print(f\"    Test - Accuracy: {model['accuracy_test']:.2f}, AUC: {model['auc_test']:.2f}, Sensitivity: {sensitivity_test:.2f}, Specificity: {specificity_test:.2f}\")\n",
    "    print(f\"    Validation - Accuracy: {model['accuracy_validation']:.2f}, AUC: {model['auc_validation']:.2f}, Sensitivity: {sensitivity_validation:.2f}, Specificity: {specificity_validation:.2f}\")\n",
    "    print(f\"    Best 'C' Value: {model['best_estimator'].get_params()['C']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc063cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
