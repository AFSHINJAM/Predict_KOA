{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "df = pd.read_excel(\"df_training.xlsx\")\n",
    "df_validation = pd.read_excel(\"df_validation.xlsx\")\n",
    "\n",
    "# Load the data into X and y\n",
    "X = df.drop('no-prog/prog', axis='columns')\n",
    "y = df[\"no-prog/prog\"]\n",
    "\n",
    "selected_features = ['Age', 'hsa-miR-556-3p', 'hsa-miR-3667-5p', 'hsa-miR-141-3p', \n",
'hsa-miR-224-5p', 'hsa-let-7c-5p', 'hsa-miR-3157-5p', 'hsa-miR-200a-5p']\n",
    "X = X[selected_features]\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103bcdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify optimal number of features in ANN model with oversampling (method 1)\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(420)\n",
    "tf.random.set_seed(420)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_validation_encoded = label_encoder.transform(df_validation['no-prog/prog'])\n",
    "\n",
    "all_features = ['Age', 'hsa-miR-556-3p', 'hsa-miR-3667-5p', 'hsa-miR-141-3p', 'hsa-miR-224-5p', \n",
    "                'hsa-let-7c-5p', 'hsa-miR-3157-5p', 'hsa-miR-200a-5p']  # List all features here\n",
    "best_model_results = {\n",
    "    'features': None,\n",
    "    'auc_test': 0,\n",
    "    'accuracy_test': 0,\n",
    "    'sen_test': 0,\n",
    "    'spe_test': 0,\n",
    "    'auc_validation': 0,\n",
    "    'accuracy_validation': 0,\n",
    "    'sen_validation': 0,\n",
    "    'spe_validation': 0\n",
    "}\n",
    "\n",
    "for i in range(3, len(all_features) + 1):\n",
    "    for subset in combinations(all_features, i):\n",
    "        X_subset = df[list(subset)]\n",
    "        X_validation_subset = df_validation[list(subset)]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_subset, y_encoded, test_size=0.2, random_state=42)\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=5, activation='relu', input_dim=X_train_resampled.shape[1]))\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      metrics=['accuracy'])\n",
    "        model.fit(X_train_resampled, y_train_resampled, epochs=170, batch_size=3, steps_per_epoch=10,\n",
    "                  validation_split=0.2, class_weight={0: 1.3, 1: 1}, verbose=0)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred_test = (model.predict(X_test) > 0.5).astype(int)\n",
    "        y_pred_validation = (model.predict(X_validation_subset) > 0.5).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        auc_validation = roc_auc_score(y_validation_encoded, y_pred_validation)\n",
    "        accuracy_validation = accuracy_score(y_validation_encoded, y_pred_validation)\n",
    "\n",
    "        # Check if this model is the best so far\n",
    "        if auc_test + auc_validation > best_model_results['auc_test'] + best_model_results['auc_validation']:\n",
    "            best_model_results['features'] = subset\n",
    "            best_model_results['auc_test'] = auc_test\n",
    "            best_model_results['accuracy_test'] = accuracy_test\n",
    "            best_model_results['auc_validation'] = auc_validation\n",
    "            best_model_results['accuracy_validation'] = accuracy_validation\n",
    "\n",
    "# Print the best model results\n",
    "print(\"Best Model Based on Combined AUC:\")\n",
    "print(f\"Features: {best_model_results['features']}\")\n",
    "print(f\"Test - Accuracy: {best_model_results['accuracy_test']:.4f}, AUC: {best_model_results['auc_test']:.4f}\")\n",
    "print(f\"Validation - Accuracy: {best_model_results['accuracy_validation']:.4f}, AUC: {best_model_results['auc_validation']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the models based on the sum of test and validation AUC, in descending order\n",
    "sorted_best_models = sorted(best_models, key=lambda x: (x['auc_test'] + x['auc_validation']), reverse=True)\n",
    "\n",
    "# Print the top 5 models\n",
    "print(\"Top 5 ANN Models Based on Combined AUC:\")\n",
    "for i, model in enumerate(sorted_best_models[:5], start=1):\n",
    "    print(f\"Model {i}:\")\n",
    "    print(f\"    Features: {model['features']}\")\n",
    "    print(f\"    Test - Accuracy: {model['accuracy_test']:.4f}, AUC: {model['auc_test']:.4f}\")\n",
    "    print(f\"    Validation - Accuracy: {model['accuracy_validation']:.4f}, AUC: {model['auc_validation']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98bb894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify optimal number of features in ANN model with oversampling (method 2)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from itertools import combinations\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(420)\n",
    "tf.random.set_seed(420)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_validation_encoded = label_encoder.transform(df_validation['no-prog/prog'])\n",
    "\n",
    "all_features = ['Age', 'hsa-miR-556-3p', 'hsa-miR-3667-5p', 'hsa-miR-141-3p', 'hsa-miR-224-5p', \n",
    "                'hsa-let-7c-5p', 'hsa-miR-3157-5p', 'hsa-miR-200a-5p']  # List all features here\n",
    "\n",
    "best_model_results = {\n",
    "    'features': None,\n",
    "    'auc_test': 0,\n",
    "    'accuracy_test': 0,\n",
    "    'sen_test': 0,\n",
    "    'spe_test': 0,\n",
    "    'auc_validation': 0,\n",
    "    'accuracy_validation': 0,\n",
    "    'sen_validation': 0,\n",
    "    'spe_validation': 0\n",
    "}\n",
    "\n",
    "for i in range(3, len(all_features) + 1):\n",
    "    for subset in combinations(all_features, i):\n",
    "        \n",
    "        X_subset = df[list(subset)]\n",
    "        X_validation_subset = df_validation[list(subset)]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_subset, y_encoded, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Apply SMOTE and scale data\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        X_validation_subset = scaler.transform(X_validation_subset)\n",
    "\n",
    "        # Create and train the ANN model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=5, activation='relu', input_dim=X_train_resampled.shape[1]))\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "        model.fit(X_train_resampled, y_train_resampled, epochs=170, batch_size=3, steps_per_epoch=10, validation_split=0.2, class_weight={0: 1.3, 1: 1}, verbose=0)\n",
    "\n",
    "        # Evaluate the model on test data\n",
    "        y_pred_test = (model.predict(X_test) > 0.5).astype(int)\n",
    "        auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "        # Evaluate and find the best threshold for the model on validation data\n",
    "        y_pred_validation_raw = model.predict(X_validation_subset)\n",
    "        best_threshold = 0.5\n",
    "        best_accuracy = 0\n",
    "        for threshold in np.linspace(0, 1, 100):\n",
    "            y_pred_validation = (y_pred_validation_raw > threshold).astype(int)\n",
    "            accuracy = accuracy_score(y_validation_encoded, y_pred_validation)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_threshold = threshold\n",
    "\n",
    "        y_pred_validation = (y_pred_validation_raw > best_threshold).astype(int)\n",
    "        auc_validation = roc_auc_score(y_validation_encoded, y_pred_validation)\n",
    "\n",
    "        # Update the best model results if the current model is better\n",
    "        if auc_test + auc_validation > best_model_results['auc_test'] + best_model_results['auc_validation']:\n",
    "            best_model_results.update({\n",
    "                'features': subset,\n",
    "                'auc_test': auc_test,\n",
    "                'accuracy_test': accuracy_test,\n",
    "                'auc_validation': auc_validation,\n",
    "                'accuracy_validation': best_accuracy\n",
    "                # Add sen_test, spe_test, sen_validation, and spe_validation calculations if needed\n",
    "            })\n",
    "\n",
    "# Print the best model results\n",
    "print(\"Best Model Based on Combined AUC:\")\n",
    "print(f\"Features: {best_model_results['features']}\")\n",
    "print(f\"Test - Accuracy: {best_model_results['accuracy_test']:.4f}, AUC: {best_model_results['auc_test']:.4f}\")\n",
    "print(f\"Validation - Accuracy: {best_model_results['accuracy_validation']:.4f}, AUC: {best_model_results['auc_validation']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the models based on the sum of test and validation AUC, in descending order\n",
    "sorted_best_models = sorted(best_models, key=lambda x: (x['auc_test'] + x['auc_validation']), reverse=True)\n",
    "\n",
    "# Print the top 5 models\n",
    "print(\"Top 5 ANN Models Based on Combined AUC:\")\n",
    "for i, model in enumerate(sorted_best_models[:5], start=1):\n",
    "    print(f\"Model {i}:\")\n",
    "    print(f\"    Features: {model['features']}\")\n",
    "    print(f\"    Test - Accuracy: {model['accuracy_test']:.4f}, AUC: {model['auc_test']:.4f}\")\n",
    "    print(f\"    Validation - Accuracy: {model['accuracy_validation']:.4f}, AUC: {model['auc_validation']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN with oversampling with optimal number of identified features in previous step\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "random.seed(420)\n",
    "tf.random.set_seed(420)\n",
    "\n",
    "selected_features = ['Age', 'hsa-miR-556-3p', 'hsa-miR-141-3p','hsa-miR-3157-5p', 'hsa-miR-200a-5p']\n",
    "X = df[selected_features]\n",
    "\n",
    "# Encode the target variable 'no-prog/prog' if it's categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(sampling_strategy=\"auto\" ,random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a Keras sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add input layer and hidden layers\n",
    "model.add(Dense(units=4, activation='relu', input_dim=X_train_resampled.shape[1]))\n",
    "model.add(Dense(units=1, activation='sigmoid'))  \n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])  \n",
    "\n",
    "# Fit the model to the training data\n",
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=170, batch_size=3, steps_per_epoch= 10,\n",
    "                    validation_split=0.2, class_weight={0: 1.3, 1: 1})\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss:.2f}')\n",
    "print(f'Test accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.round(y_pred).astype(int)  \n",
    "\n",
    "# Calculate classification report\n",
    "report = classification_report(y_test, y_pred_classes)\n",
    "print(report)\n",
    "\n",
    "# Calculate and print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate AUC\n",
    "auc_modeling = roc_auc_score(y_test, y_pred)\n",
    "print(f'AUC: {auc_modeling:.4f}')\n",
    "\n",
    "# Access the weights of the first dense layer\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "\n",
    "# Calculate feature importance by taking the absolute values of weights and summing them along the axis\n",
    "feature_importance = np.sum(np.abs(weights), axis=0)\n",
    "\n",
    "# Create a list of feature names corresponding to selected_vars\n",
    "feature_names = selected_features\n",
    "\n",
    "# Sort feature importance and feature names in descending order\n",
    "sorted_indices = np.argsort(feature_importance)[::-1]  \n",
    "sorted_feature_importance = feature_importance[sorted_indices]\n",
    "sorted_feature_names = [feature_names[i] for i in sorted_indices]\n",
    "\n",
    "# Create a bar plot to visualize sorted feature importance\n",
    "plt.figure(figsize=(3, 2))\n",
    "plt.barh(sorted_feature_names, sorted_feature_importance)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance Plot')\n",
    "plt.gca().invert_yaxis()  \n",
    "plt.show()\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Extract TP, TN, FP, FN values from the confusion matrix\n",
    "TP = conf_matrix[1, 1]\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "\n",
    "# Calculate sensitivity (sen) and specificity (spe)\n",
    "sen = TP / (TP + FN)\n",
    "spe = TN / (TN + FP)\n",
    "\n",
    "# Print sensitivity and specificity\n",
    "print(f'Sensitivity (Sen): {sen:.4f}')\n",
    "print(f'Specificity (Spe): {spe:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb189c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating ANN with oversampling on external data\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\n",
    "\n",
    "selected_vars = ['Age', 'hsa-miR-556-3p', 'hsa-miR-141-3p','hsa-miR-3157-5p', 'hsa-miR-200a-5p']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_validation_scaled = scaler.fit_transform(df_validation[selected_vars])\n",
    "y_validation = df_validation[\"no-prog/prog\"]\n",
    "\n",
    "y_validation_encoded = label_encoder.transform(df_validation[\"no-prog/prog\"])\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "validation_loss, _ = model.evaluate(X_validation_scaled, y_validation_encoded)\n",
    "print(f'Validation loss: {validation_loss:.4f}')\n",
    "\n",
    "# Calculate AUC\n",
    "y_pred_validation = model.predict(X_validation_scaled)\n",
    "auc_val = roc_auc_score(y_validation_encoded, y_pred_validation)\n",
    "print(f'AUC: {auc_val:.4f}')\n",
    "\n",
    "# Initialize variables to track the best threshold and accuracy\n",
    "best_threshold = 0.5  # Start with a default threshold of 0.5\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate through a range of threshold values\n",
    "thresholds = np.linspace(0, 1, 100)  # Consider 101 threshold values between 0 and 1\n",
    "for threshold in thresholds:\n",
    "    y_pred_classes_validation = (y_pred_validation > threshold).astype(int)\n",
    "    validation_accuracy = accuracy_score(y_validation_encoded, y_pred_classes_validation)\n",
    "    \n",
    "    if validation_accuracy > best_accuracy:\n",
    "        best_accuracy = validation_accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Apply the best threshold\n",
    "y_pred_classes_best_threshold = (y_pred_validation > best_threshold).astype(int)\n",
    "\n",
    "# Calculate the confusion matrix for the best threshold\n",
    "conf_matrix_best_threshold = confusion_matrix(y_validation_encoded, y_pred_classes_best_threshold)\n",
    "print(f'Best Threshold for Highest Accuracy: {best_threshold:.2f}')\n",
    "print(f'Highest Validation Accuracy: {best_accuracy:.2f}')\n",
    "print(f'Confusion Matrix for Best Threshold:')\n",
    "print(conf_matrix_best_threshold)\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "true_positive = conf_matrix_best_threshold[1, 1]\n",
    "false_negative = conf_matrix_best_threshold[1, 0]\n",
    "true_negative = conf_matrix_best_threshold[0, 0]\n",
    "false_positive = conf_matrix_best_threshold[0, 1]\n",
    "\n",
    "sensitivity = true_positive / (true_positive + false_negative)\n",
    "specificity = true_negative / (true_negative + false_positive)\n",
    "\n",
    "print(f'Sensitivity: {sensitivity:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "\n",
    "\n",
    "# Access the weights of the first dense layer\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "\n",
    "# Calculate feature importance by taking the absolute values of weights and summing them along the axis\n",
    "feature_importance = np.sum(np.abs(weights), axis=0)\n",
    "\n",
    "# Create a list of feature names corresponding to selected_vars\n",
    "feature_names = selected_vars\n",
    "\n",
    "# Sort feature importance and feature names in descending order\n",
    "sorted_indices = np.argsort(feature_importance)[::-1]  \n",
    "sorted_feature_importance = feature_importance[sorted_indices]\n",
    "sorted_feature_names = [feature_names[i] for i in sorted_indices]\n",
    "\n",
    "# Create a bar plot to visualize sorted feature importance\n",
    "plt.figure(figsize=(3, 2))\n",
    "plt.barh(sorted_feature_names, sorted_feature_importance)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()  \n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Get the false positive rate, true positive rate, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_validation_encoded, y_pred_validation)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc_val:.4f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "plt.title('ROC Curve - Validation Data')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot for predicted probabilities\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot points for non-progressors\n",
    "non_prog_indices = np.where(y_validation_encoded == 0)[0]\n",
    "plt.scatter(non_prog_indices, y_pred_validation[non_prog_indices], color='green', label='Non-Progressor')\n",
    "\n",
    "# Plot points for progressors\n",
    "prog_indices = np.where(y_validation_encoded == 1)[0]\n",
    "plt.scatter(prog_indices, y_pred_validation[prog_indices], color='red', label='Progressor')\n",
    "\n",
    "plt.axhline(y=0.56, color='r', linestyle='--', label='Threshold = 0.62')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Predicted Probability')\n",
    "plt.title('Scatter Plot of Predicted Probabilities - Validation Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3997b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating ANN with oversampling on external data ( generating AUC and ACC plots)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 0.62\n",
    "\n",
    "# Apply the threshold to get binary predictions\n",
    "y_pred_classes = (y_pred > threshold).astype(int)\n",
    "y_pred_validation_classes = (y_pred_validation > threshold).astype(int)\n",
    "\n",
    "# Calculate accuracy for the test data\n",
    "accuracy_test = accuracy_score(y_test, y_pred_classes)\n",
    "\n",
    "# Calculate accuracy for the validation data\n",
    "accuracy_validation = accuracy_score(y_validation_encoded, y_pred_classes_best_threshold)\n",
    "\n",
    "# Calculate ROC curve for the test data\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_pred)\n",
    "\n",
    "# Apply the new threshold to get binary predictions\n",
    "y_pred_classes_new_threshold = (y_pred_validation > threshold).astype(int)\n",
    "\n",
    "# Calculate the confusion matrix for the new threshold\n",
    "conf_matrix_new_threshold = confusion_matrix(y_validation_encoded, y_pred_classes_new_threshold)\n",
    "\n",
    "print(f'Confusion Matrix for New Threshold (={threshold}):')\n",
    "print(conf_matrix_new_threshold)\n",
    "\n",
    "# Extract TP, TN, FP, FN values from the new confusion matrix\n",
    "TP_new = conf_matrix_new_threshold[1, 1]\n",
    "TN_new = conf_matrix_new_threshold[0, 0]\n",
    "FP_new = conf_matrix_new_threshold[0, 1]\n",
    "FN_new = conf_matrix_new_threshold[1, 0]\n",
    "\n",
    "# Calculate sensitivity (sen) and specificity (spe) for the new threshold\n",
    "sen_new = TP_new / (TP_new + FN_new)\n",
    "spe_new = TN_new / (TN_new + FP_new)\n",
    "\n",
    "# Print sensitivity and specificity for the new threshold\n",
    "print(f'Sensitivity (Sen) for New Threshold (={threshold}): {sen_new:.2f}')\n",
    "print(f'Specificity (Spe) for New Threshold (={threshold}): {spe_new:.2f}')\n",
    "\n",
    "\n",
    "# Plot ROC curves and accuracy for test and validation data\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr_test, tpr_test, color='darkorange', lw=2, label=f'Test AUC = {roc_auc_score(y_test, y_pred):.2f}')\n",
    "plt.plot(fpr, tpr, color='darkgreen', lw=2, label=f'Validation AUC = {auc_val:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "bars = plt.bar(['Test', 'Validation'], [accuracy, best_accuracy], color=['darkorange', 'darkgreen'])\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Test and Validation Data')\n",
    "\n",
    "# Add accuracy values on top of the bars\n",
    "for bar, acc in zip(bars, [accuracy, best_accuracy]):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.02, f'{acc:.2f}', color='black', fontsize=10)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc69236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte carlo cross-validation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import random\n",
    "\n",
    "selected_features = ['Age', 'hsa-miR-556-3p', 'hsa-miR-141-3p','hsa-miR-3157-5p', 'hsa-miR-200a-5p']\n",
    "X = df[selected_features]\n",
    "\n",
    "# Encode the target variable 'no-prog/prog' if it's categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Specify the seed for reproducibility\n",
    "seed = 123\n",
    "\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seeds(seed=123):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "# Set seeds initially\n",
    "set_seeds(seed)\n",
    "\n",
    "# Specify the number of simulations you want to try\n",
    "num_simulations = 30\n",
    "\n",
    "# Lists to store results for each simulation\n",
    "auc_values = []\n",
    "accuracy_values = []\n",
    "sensitivity_values = []\n",
    "specificity_values = []\n",
    "\n",
    "# Lists to store ROC curve values\n",
    "all_fpr = []\n",
    "mean_tpr = []\n",
    "\n",
    "# Plot accuracy for each simulation\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for sim_num in range(1, num_simulations + 1):\n",
    "    print(f\"\\n--- Running Simulation {sim_num} ---\")\n",
    "\n",
    "    # Set seeds for reproducibility in each simulation\n",
    "    set_seeds(seed + sim_num)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(sampling_strategy=\"auto\", random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Create a Keras sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add input layer and hidden layers\n",
    "    model.add(Dense(units=5, activation='relu', input_dim=X_train_resampled.shape[1]))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    history = model.fit(X_train_resampled, y_train_resampled, epochs=170, batch_size=12, steps_per_epoch=10,\n",
    "                        validation_split=0, class_weight={0: 1.3, 1: 1})\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'Test loss: {loss:.2f}')\n",
    "    print(f'Test accuracy: {accuracy:.2f}')\n",
    "    \n",
    "    # Store accuracy value for each simulation\n",
    "    accuracy_values.append(accuracy)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.round(y_pred).astype(int)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc_modeling = roc_auc_score(y_test, y_pred)\n",
    "    auc_values.append(auc_modeling)\n",
    "    print(f'AUC: {auc_modeling:.4f}')\n",
    "\n",
    "    # Calculate classification report\n",
    "    report = classification_report(y_test, y_pred_classes)\n",
    "    print(report)\n",
    "\n",
    "    # Calculate and print confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Calculate sensitivity (sen) and specificity (spe)\n",
    "    TP = conf_matrix[1, 1]\n",
    "    TN = conf_matrix[0, 0]\n",
    "    FP = conf_matrix[0, 1]\n",
    "    FN = conf_matrix[1, 0]\n",
    "    sen = TP / (TP + FN)\n",
    "    spe = TN / (TN + FP)\n",
    "    sensitivity_values.append(sen)\n",
    "    specificity_values.append(spe)\n",
    "    print(f'Sensitivity (Sen): {sen:.4f}')\n",
    "    print(f'Specificity (Spe): {spe:.4f}')\n",
    "    \n",
    "    # Calculate ROC curve values with more threshold points\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, drop_intermediate=False)\n",
    "\n",
    "    # Interpolate ROC curve values for a smoother curve\n",
    "    interp_fpr = np.linspace(0, 1, 10000)\n",
    "    interp_tpr = np.interp(interp_fpr, fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve for each simulation\n",
    "    plt.plot(interp_fpr, interp_tpr, color='black', alpha=0.5)\n",
    "\n",
    "    # Store ROC curve values for each simulation\n",
    "    all_fpr.append(interp_fpr)\n",
    "    mean_tpr.append(interp_tpr)\n",
    "\n",
    "# Calculate average AUC, accuracy, sensitivity, and specificity\n",
    "average_auc = np.mean(auc_values)\n",
    "average_accuracy = np.mean(accuracy_values)\n",
    "average_sensitivity = np.mean(sensitivity_values)\n",
    "average_specificity = np.mean(specificity_values)\n",
    "\n",
    "# Print average results\n",
    "print(f'\\nAverage AUC over all simulations: {average_auc:.4f}')\n",
    "print(f'Average accuracy over all simulations: {average_accuracy:.4f}')\n",
    "print(f'Average Sensitivity over all simulations: {average_sensitivity:.4f}')\n",
    "print(f'Average Specificity over all simulations: {average_specificity:.4f}')\n",
    "\n",
    "# Plot averaged ROC curve\n",
    "mean_tpr = np.mean(mean_tpr, axis=0)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='black')\n",
    "plt.plot(interp_fpr, mean_tpr, color='red', label=f'Averaged ROC Curve (AUC = {average_auc:.2f})')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'Averaged ROC Curve\\nAverage AUC: {average_auc:.2f}, SEN: {average_sensitivity:.2f}, SPE: {average_specificity:.2f}, Accuracy: {average_accuracy:.2f}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy for each simulation as bars\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(1, num_simulations + 1), accuracy_values, color='black', alpha=0.7)\n",
    "plt.xlabel('Simulation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Each Simulation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dfb7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identifying logistic regression coefficients for the ANN model with oversampling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "selected_features = ['Age', 'hsa-miR-556-3p', 'hsa-miR-141-3p','hsa-miR-3157-5p', 'hsa-miR-200a-5p']\n",
    "X = df[selected_features]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Calculate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Calculate and print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate AUC\n",
    "auc_modeling = roc_auc_score(y_test, y_pred)\n",
    "print(f'AUC: {auc_modeling:.4f}')\n",
    "\n",
    "# Access coefficients and intercept\n",
    "coefficients = log_reg.coef_\n",
    "intercept = log_reg.intercept_\n",
    "\n",
    "# Calculate p-values using statsmodels (optional)\n",
    "import statsmodels.api as sm\n",
    "X_train_sm = sm.add_constant(X_train_scaled)\n",
    "log_reg_sm = sm.Logit(y_train, X_train_sm)\n",
    "result = log_reg_sm.fit()\n",
    "p_values = result.pvalues\n",
    "\n",
    "# Print coefficients and p-values\n",
    "print(\"Feature \\t Coefficient \\t P-value\")\n",
    "for feature, coef, p_value in zip(selected_features, coefficients[0], p_values[1:]):\n",
    "    print(f\"{feature} \\t {coef:.4f} \\t\\t {p_value:.4f}\")\n",
    "\n",
    "\n",
    "# Visualize coefficients\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(selected_features, coefficients[0])\n",
    "plt.xlabel('Coefficients')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8fe58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identifying logistic regression coefficients (without train/test) for the ANN model with oversampling\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Fit the model to all data\n",
    "log_reg.fit(X_scaled, y_encoded)\n",
    "\n",
    "# Access coefficients and intercept\n",
    "coefficients = log_reg.coef_\n",
    "intercept = log_reg.intercept_\n",
    "\n",
    "# Calculate p-values using statsmodels\n",
    "X_sm = sm.add_constant(X_scaled)\n",
    "log_reg_sm = sm.Logit(y_encoded, X_sm)\n",
    "result = log_reg_sm.fit()\n",
    "p_values = result.pvalues\n",
    "\n",
    "# Print coefficients and p-values\n",
    "print(\"Feature \\t Coefficient \\t P-value\")\n",
    "for feature, coef, p_value in zip(selected_features, coefficients[0], p_values[1:]):\n",
    "    print(f\"{feature} \\t {coef:.4f} \\t\\t {p_value:.5f}\")\n",
    "\n",
    "# Visualize coefficients\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(selected_features, coefficients[0])\n",
    "plt.xlabel('Coefficients')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
